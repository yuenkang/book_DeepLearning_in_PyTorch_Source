{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuenkang/book_DeepLearning_in_PyTorch_Source/blob/master/02_DL_meets_PyTorch/%E5%88%9D%E8%AF%86PyTorch%20basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygc5IA8cb8W7"
      },
      "source": [
        "# 第一课 当深度学习遇上PyTorch\n",
        "\n",
        "在这节课中，我们主要展示了PyTorch的使用方法，以及如何用PyTorch实现一个线性回归算法\n",
        "\n",
        "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTExsI4Fb8W8"
      },
      "source": [
        "## 一、有关Tensor和Autograd变量的练习\n",
        "### 1. Tensor\n",
        "#### a. 产生Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aRUoGGoSb8W8",
        "outputId": "08291555-41e7-4430-bc43-19460bb4408d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import torch  #导入torch包\n",
        "torch.__version__ #显示当前PyTorch版本号，笔者用的是0.1.12_2，有些命令可能在新的版本下无法执行，请参考PyTorch文件找到最新的相应命令"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "V8lzb4CMb8W9",
        "outputId": "daac3231-b175-4000-d001-305f12d476cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7299, 0.0586, 0.6780],\n",
              "        [0.5308, 0.7961, 0.5878],\n",
              "        [0.1012, 0.1000, 0.7280],\n",
              "        [0.3891, 0.0637, 0.8353],\n",
              "        [0.8640, 0.0618, 0.9292]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "x = torch.rand(5, 3)  #产生一个5*3的tensor，随机取值\n",
        "x  #显示x的值"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tT_Cv8Ymb8W9",
        "outputId": "12d90c63-c7c9-492d-f1a5-b1439fdc1398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y = torch.ones(5, 3) #产生一个5*3的Tensor，元素都是1\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "L6sH21Fbb8W9",
        "outputId": "e9b84449-75d5-40a7-d2bb-bbcffc0520a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "z = torch.zeros(2, 5, 3) #产生一个5*3的Tensor，元素都是1\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "U8IpdoiJb8W9",
        "outputId": "2b6fc1f4-af31-48a4-daf7-1a245c6500aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "z[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EXZhlJsWb8W9",
        "outputId": "19017167-972d-41b4-b64f-adfa4d89d2f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5878)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "x[1,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "x51SRzCwb8W-",
        "outputId": "b417f807-46ae-4bf2-ff4e-d7eb2cf56c3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6780, 0.5878, 0.7280, 0.8353, 0.9292])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "x[:,2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8yIhKSgb8W-"
      },
      "source": [
        "#### b. Tensor的运算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PVZWgluab8W-",
        "outputId": "9e0c5975-052a-4ab5-b3f3-0dbb14be8e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.7299, 1.0586, 1.6780],\n",
              "        [1.5308, 1.7961, 1.5878],\n",
              "        [1.1012, 1.1000, 1.7280],\n",
              "        [1.3891, 1.0637, 1.8353],\n",
              "        [1.8640, 1.0618, 1.9292]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#x = torch.FloatTensor([[0.3297,0.7021,0.1119],[0.6668,0.6904,0.1953],[0.6683,0.4260,0.2950],[0.0899,0.4099,0.0882],[0.4675,0.8369,0.1926]])\n",
        "z = x + y #两个tensor可以直接相加\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xerQdA7Xb8W-"
      },
      "source": [
        "下面的语句展示了两个tensor按照矩阵的方式相乘，注意x的尺寸是5*3，y的尺寸也是5*3无法进行矩阵乘法，所以先将y进行转置。\n",
        "转置操作可以用.t来完成，也可以用<!-- lang:python-->.transpose(0, 1)来完成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "mu-QXV0ob8W-",
        "outputId": "e00b0394-21b9-4137-a172-ee9710f5df2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4664, 1.4664, 1.4664, 1.4664, 1.4664],\n",
              "        [1.9147, 1.9147, 1.9147, 1.9147, 1.9147],\n",
              "        [0.9293, 0.9293, 0.9293, 0.9293, 0.9293],\n",
              "        [1.2881, 1.2881, 1.2881, 1.2881, 1.2881],\n",
              "        [1.8551, 1.8551, 1.8551, 1.8551, 1.8551]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "q = x.mm(y.t()) #x乘以y的转置\n",
        "q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hq-uJumb8W-"
      },
      "source": [
        "#### c. Tensor与numpy.ndarray之间的转换"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "sSUxF8Bvb8W-",
        "outputId": "675e4a2c-b360-47e1-b31c-e0ea67456e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import numpy as np #导入numpy包\n",
        "a = np.ones([5, 3]) #建立一个5*3全是1的二维数组（矩阵）\n",
        "b = torch.from_numpy(a) #利用from_numpy将其转换为tensor\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9Z2NRVk9b8W-",
        "outputId": "cbde9639-368b-450b-8e72-eb960c2c01c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "c = torch.FloatTensor(a) #另外一种转换为tensor的方法，类型为FloatTensor，还可以使LongTensor，整型数据类型\n",
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "s_L09bHgb8W-",
        "outputId": "44dfbcd3-485b-41aa-eeb5-54d131932397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "b.numpy()  #从一个tensor转化为numpy的多维数组"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3G2fQEqb8W-"
      },
      "source": [
        "tensor和numpy的最大区别在于tensor可以在GPU上运算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Xm_YY0tlb8W-",
        "outputId": "8c39816d-77a9-42ef-ba42-d55b5402bea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.7299, 1.0586, 1.6780],\n",
            "        [1.5308, 1.7961, 1.5878],\n",
            "        [1.1012, 1.1000, 1.7280],\n",
            "        [1.3891, 1.0637, 1.8353],\n",
            "        [1.8640, 1.0618, 1.9292]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():  #检测本机器上有无GPU可用\n",
        "    x = x.cuda() #返回x的GPU上运算的版本\n",
        "    y = y.cuda()\n",
        "    print(x + y) #tensor可以在GPU上正常运算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EZSEATSsb8W-",
        "outputId": "fc331807-d915-4332-f763-bc71d1890294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.7299, 1.0586, 1.6780],\n",
            "        [1.5308, 1.7961, 1.5878],\n",
            "        [1.1012, 1.1000, 1.7280],\n",
            "        [1.3891, 1.0637, 1.8353],\n",
            "        [1.8640, 1.0618, 1.9292]], device='cuda:0')\n",
            "tensor([[1.7299, 1.0586, 1.6780],\n",
            "        [1.5308, 1.7961, 1.5878],\n",
            "        [1.1012, 1.1000, 1.7280],\n",
            "        [1.3891, 1.0637, 1.8353],\n",
            "        [1.8640, 1.0618, 1.9292]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():  #检测本机器上有无GPU可用\n",
        "    device = torch.device(\"cuda\")          # 选择一个CUDA设备\n",
        "    y = torch.ones_like(x, device=device)  # 在GPU上直接创建张量\n",
        "    x = x.to(device)                       # 也可以直接加载``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # 转回到CPU上``.to``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khHqUpJHb8W-"
      },
      "source": [
        "### 2. 有关自动微分变量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "v90hIyN1b8W-",
        "outputId": "ca2f0778-f4ae-4f85-cb53-60072644a915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "x = torch.ones((2, 2), requires_grad=True)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZgPNhI-xb8W_",
        "outputId": "cea8bd39-5d83-4551-a4d3-71021275757e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AddBackward0 at 0x7ee14b69d360>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "y = x + 2  #可以按照Tensor的方式进行计算\n",
        "y.grad_fn\n",
        "#注：在新版本PyTorch中，可以用.grad_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "agrs_mRRb8W_",
        "outputId": "48785356-dd6b-4aff-f8f1-740fcf6c4a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MulBackward0 at 0x7ee14b69fdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "z = y * y  #可以进行各种符合运算\n",
        "z.grad_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ksGOmfP9b8W_",
        "outputId": "af7404dc-502c-427b-9fd0-0cebf1e97da3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "z = torch.mean(y * y)  #也可以进行复合运算\n",
        "z.data #.data属性可以返回z所包裹的tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2eLj2L4b8W_"
      },
      "source": [
        "** backward可以实施反向传播算法，并计算所有计算图上叶子节点的导数（梯度）信息。注意，由于z和y都不是叶子节点，所以都没有梯度信息）**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "IjvFxV64b8W_",
        "outputId": "cb489010-dab7-4a7f-a1b4-6d5d563ded34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "tensor([[1.5000, 1.5000],\n",
            "        [1.5000, 1.5000]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-5343f8f4e899>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(z.grad)\n",
            "<ipython-input-42-5343f8f4e899>:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(y.grad)\n"
          ]
        }
      ],
      "source": [
        "z.backward() #梯度反向传播\n",
        "print(z.grad)\n",
        "print(y.grad)\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHBmR1uwb8W_"
      },
      "source": [
        "在下面的例子中，我们让矩阵x反复作用在向量x上，系统会自动记录中间的依赖关系和长路径"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "jLqJLMg2b8W_"
      },
      "outputs": [],
      "source": [
        "s = torch.tensor([[0.01, 0.02]], requires_grad = True) #创建一个1*2的tensor（1维向量）\n",
        "x = torch.ones(2, 2, requires_grad = True) #创建一个2*2的矩阵型tensor\n",
        "for i in range(10):\n",
        "    s = s.mm(x)  #反复用s乘以x（矩阵乘法），注意s始终是1*2的tensor\n",
        "z = torch.mean(s) #对s中的各个元素求均值，得到一个1*1的scalar（标量，即1*1张量）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_zEU6o82b8W_",
        "outputId": "617c3212-18c6-43cf-cb8a-7d722829a6d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[37.1200, 37.1200],\n",
            "        [39.6800, 39.6800]])\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-85aff1ec9fe2>:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(s.grad)  #s不是叶节点，没有梯度信息\n"
          ]
        }
      ],
      "source": [
        "z.backward() #在具有很长的依赖路径的计算图上用反向传播算法计算叶节点的梯度\n",
        "print(x.grad)  #x作为叶节点可以获得这部分梯度信息\n",
        "print(s.grad)  #s不是叶节点，没有梯度信息"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lySATaWvb8W_"
      },
      "source": [
        "## 二、利用PyTorch实现简单的线性回归算法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZAZdNHmb8W_"
      },
      "source": [
        "### 1. 准备数据\n",
        "\n",
        "在这里，我们人为生成一些样本点作为我们的原始数据\n",
        "\n",
        "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "oQtykTehb8W_"
      },
      "outputs": [],
      "source": [
        "x = torch.linspace(0, 100, steps=100).type(torch.FloatTensor) #linspace可以生成0-100之间的均匀的100个数字\n",
        "rand = torch.randn(100) * 10 #随机生成100个满足标准正态分布的随机数，均值为0，方差为1.将这个数字乘以10，标准方差变为10\n",
        "y = x + rand #将x和rand相加，得到伪造的标签数据y。所以(x,y)应能近似地落在y=x这条直线上"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVOT8Uqub8W_"
      },
      "source": [
        "划分数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "NH9lqWn3b8W_"
      },
      "outputs": [],
      "source": [
        "x_train = x[: -10]\n",
        "x_test = x[-10 :]\n",
        "y_train = y[: -10]\n",
        "y_test = y[-10 :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ihwQU9b8W_"
      },
      "source": [
        "将生成的训练数据点画在图上"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "0E54-13sb8W_",
        "outputId": "b10a85a8-ad76-4d88-f422-ac551fd580a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt #导入画图的程序包\n",
        "plt.figure(figsize=(10,8)) #设定绘制窗口大小为10*8 inch\n",
        "plt.plot(x_train.numpy(), y_train.numpy(), 'o')\n",
        "plt.xlabel('X') #添加X轴的标注\n",
        "plt.ylabel('Y') #添加Y周的标注\n",
        "plt.show() #将图形画在下面"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUCmleW8b8W_"
      },
      "source": [
        "### 2. 构造模型，计算损失函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzsqKJjhb8W_"
      },
      "source": [
        "在下面的代码中，需要注意expand_as和mul的使用。首先，a的维度为1，x的维度为100*1的Tensor，这两者不能直接相乘，因为维度不同。\n",
        "\n",
        "所以，先要将a升维成1*1的Tensor。这就好比将原本在直线上的点被升维到了二维平面上，同时直线仍然在二维平面中。\n",
        "\n",
        "```expand_as(x)```可以将张量升维成与x同维度的张量。所以如果a = 1, x为尺寸为100，那么，\n",
        "\n",
        "a.expand_as(x)$ = (1, 1, \\cdot\\cdot\\cdot, 1)^T$\n",
        "\n",
        "```x * y```为两个1维张量的乘积，计算结果：\n",
        "\n",
        "$(x * y)_i = x_i \\cdot y_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ODwBmtu5b8XC",
        "outputId": "57de921c-64cb-49b5-be35-ea9f0638adc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4366, 0.5033, 0.5701, 0.6368, 0.7035, 0.7703, 0.8370, 0.9038, 0.9705,\n",
              "        1.0373, 1.1040, 1.1707, 1.2375, 1.3042, 1.3710, 1.4377, 1.5044, 1.5712,\n",
              "        1.6379, 1.7047, 1.7714, 1.8382, 1.9049, 1.9716, 2.0384, 2.1051, 2.1719,\n",
              "        2.2386, 2.3054, 2.3721, 2.4388, 2.5056, 2.5723, 2.6391, 2.7058, 2.7726,\n",
              "        2.8393, 2.9060, 2.9728, 3.0395, 3.1063, 3.1730, 3.2398, 3.3065, 3.3732,\n",
              "        3.4400, 3.5067, 3.5735, 3.6402, 3.7070, 3.7737, 3.8404, 3.9072, 3.9739,\n",
              "        4.0407, 4.1074, 4.1742, 4.2409, 4.3076, 4.3744, 4.4411, 4.5079, 4.5746,\n",
              "        4.6414, 4.7081, 4.7748, 4.8416, 4.9083, 4.9751, 5.0418, 5.1086, 5.1753,\n",
              "        5.2420, 5.3088, 5.3755, 5.4423, 5.5090, 5.5758, 5.6425, 5.7092, 5.7760,\n",
              "        5.8427, 5.9095, 5.9762, 6.0430, 6.1097, 6.1764, 6.2432, 6.3099, 6.3767],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "a = torch.rand(1, requires_grad = True)\n",
        "b = torch.rand(1, requires_grad = True)\n",
        "predictions = a.expand_as(x_train) * x_train + b.expand_as(x_train)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "n5Q5O7Rab8XD"
      },
      "outputs": [],
      "source": [
        "loss = torch.mean((predictions - y_train) ** 2)  #计算损失函数\n",
        "loss.backward() #开始反向传播梯度\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "YGT1i87nb8XD",
        "outputId": "2f22ddde-ef34-4335-d319-57524c8be385",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5191])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "#开始梯度下降，其中0.001为学习率\n",
        "a.data.add_(- 0.001 * a.grad.data)\n",
        "b.data.add_(- 0.001 * b.grad.data)\n",
        "\n",
        "#注意我们无法改变一个tensor，而只能对tensor的data属性做更改\n",
        "#所有函数加“_”都意味着需要更新调用者的数值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55sauSCib8XD"
      },
      "source": [
        "### 3. 训练模型的代码"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esvA8ozib8XD"
      },
      "source": [
        "#### a. 错误版本\n",
        "\n",
        "错误在于，每一步迭代周期没有将a和b的梯度（grad）数值设置为0，导致每一步backward候梯度就会不断累加"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "U5jo54JDb8XD",
        "outputId": "e8d0f6be-fbf9-42f6-e373-1da6774f0f6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial parameters: tensor([0.9564], requires_grad=True) tensor([0.1108], requires_grad=True)\n",
            "loss: tensor(113.5731, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8565, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5145, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1881, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8666, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2784, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2741, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7359, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0500, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7536, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1505, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2451, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1118, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2522, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1513, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7465, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0481, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7426, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2766, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2717, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1939, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5185, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8507, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5679, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5776, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5100, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1817, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8696, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2844, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2711, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7286, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0512, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1490, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2374, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1111, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2586, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1516, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7388, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0456, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7486, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2785, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2645, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8587, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1990, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5218, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8443, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5815, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8662, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5048, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1746, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8719, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2898, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2674, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7207, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0518, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7659, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1470, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2291, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1099, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2645, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1513, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7306, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0425, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7541, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2799, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2568, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8538, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2037, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5247, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8375, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5558, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5850, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8703, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4993, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1671, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8738, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2948, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2634, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7124, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0520, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7714, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1446, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2204, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1083, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2700, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1506, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7220, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0390, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7592, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2809, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2487, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8486, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2080, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5273, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8304, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5491, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5880, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8741, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4934, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1593, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8754, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2995, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2590, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7039, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0519, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7766, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1421, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2115, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1064, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2753, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1498, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7132, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0354, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7641, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2818, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2405, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8434, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2121, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5297, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8232, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5424, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5910, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8778, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4875, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1515, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8769, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3042, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2547, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6953, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0518, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7819, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1395, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2026, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1045, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2806, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1491, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7045, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0317, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7691, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2828, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2324, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8381, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2163, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5323, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8161, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5357, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5941, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8817, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4818, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1437, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8786, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3091, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2506, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6869, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0518, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7873, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1372, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1939, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1028, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2862, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1486, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6960, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0283, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7744, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2842, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2246, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8331, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2209, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5353, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8093, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5293, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5975, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8860, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4765, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1364, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8806, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3144, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2470, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6788, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0522, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7932, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1354, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1857, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1015, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2923, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1487, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6880, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0254, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7801, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2860, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2173, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8286, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2259, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5387, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8031, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5235, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6015, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8909, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4717, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1295, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8832, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3202, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2439, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6714, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0532, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.7996, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1341, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1780, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1008, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.2989, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1493, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6806, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0230, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7864, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2885, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2106, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8246, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2315, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5428, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7975, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5182, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6060, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.8963, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4675, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1232, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8863, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3267, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2414, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6645, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0548, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8067, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1335, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1710, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1007, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3061, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1506, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6739, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0212, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.7934, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2916, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.2045, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8213, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2378, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5476, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7926, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5136, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6112, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9025, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4640, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1176, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8901, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3338, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2396, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6583, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0570, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8144, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1336, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1646, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1012, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3140, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1525, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6677, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0200, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8009, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2953, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1991, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8186, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2446, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5529, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7882, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5096, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6169, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9092, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1126, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8944, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3415, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2384, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6526, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8227, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1342, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1587, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1022, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3224, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1550, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0193, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8090, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2996, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1942, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8163, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2519, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5588, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7844, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5060, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6230, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9164, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4587, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1079, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8991, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3496, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2376, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6473, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8314, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1352, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1532, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1035, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3311, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1579, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6569, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0189, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8174, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3042, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1896, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8143, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2595, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5650, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7809, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.5026, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6295, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9238, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4565, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.1035, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9041, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3580, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2371, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6422, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0660, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8403, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1364, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1479, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1050, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3400, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6518, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0187, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8259, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3090, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1851, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8124, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2671, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5713, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7774, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4993, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6359, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9313, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4544, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0991, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9090, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3664, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2366, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6372, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0692, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8491, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1377, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1426, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1064, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3488, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1639, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6466, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0183, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8342, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3136, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1805, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8103, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2746, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5774, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7738, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4958, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6421, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9387, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4522, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0945, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9137, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3746, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2359, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6318, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0721, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8576, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1386, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1369, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1075, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3574, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1666, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6410, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0175, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8423, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3180, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1755, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8079, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2817, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5832, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7698, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4919, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6480, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9456, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4495, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0895, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9180, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3823, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2348, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6260, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0746, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8658, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1392, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1308, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1081, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3654, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1688, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6351, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0163, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8498, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3218, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1701, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8049, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2883, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5885, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7654, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4875, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6532, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9520, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4463, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0839, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9216, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3895, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2331, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6197, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0765, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8733, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1392, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1241, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1080, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3729, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1705, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6285, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0144, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8567, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3251, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1641, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.8013, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2942, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5932, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4823, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6578, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9578, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4425, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0776, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9246, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.3961, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2308, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6126, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0776, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8802, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1385, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1167, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1073, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3797, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1716, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6213, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0118, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3277, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1575, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7970, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.2995, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.5972, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7546, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4766, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4381, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0707, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9269, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4020, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2279, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.6050, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0782, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8865, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1373, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1088, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1060, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3858, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1720, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6134, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0086, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8686, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3298, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1502, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7921, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3042, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6007, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7483, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4702, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6651, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9677, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4332, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9287, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4074, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2245, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5968, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0782, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8923, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1356, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.1003, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1041, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3915, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1720, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.6052, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0049, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8737, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3315, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1425, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7868, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3084, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6038, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7417, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4634, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6680, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9719, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4278, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0553, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9300, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4125, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2208, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5882, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0778, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.8977, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1336, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0915, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.1019, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.3969, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1718, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5965, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0009, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8786, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3329, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1346, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7811, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3123, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6067, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7348, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4564, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6708, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9760, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4223, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0472, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9312, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4174, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2169, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5795, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0772, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9030, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1314, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0825, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0995, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4022, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1714, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5878, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9968, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8834, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3342, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1266, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7754, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3162, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6095, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7279, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4493, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6734, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9800, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4168, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0392, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9324, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4223, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2130, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5708, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0767, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9083, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1294, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0737, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0972, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4075, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1712, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5793, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9928, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8883, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3357, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1188, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7698, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3203, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6126, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7212, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4425, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6763, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9843, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4116, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0313, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9337, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4275, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2095, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0764, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9140, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1277, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0652, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0952, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4132, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1713, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5711, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9891, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8935, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3376, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1114, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7646, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3247, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6161, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7149, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4360, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6795, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9891, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4068, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0239, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9355, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4331, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2065, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5544, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0765, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9201, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1265, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0572, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0937, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4193, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1720, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5635, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9859, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.8993, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3401, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.1045, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3297, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6201, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7092, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4300, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6833, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.9944, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.4026, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0171, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9379, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4393, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2040, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5471, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0773, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9269, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1260, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0497, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0927, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4261, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1733, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5564, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9833, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9057, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3432, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0983, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7558, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3353, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6248, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.7042, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4247, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6878, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0004, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3991, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0108, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9409, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4462, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2022, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5403, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0787, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9342, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1261, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0429, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0924, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4336, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1753, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5500, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9813, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9127, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3469, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0927, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7524, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3415, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6301, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6998, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4200, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6928, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0070, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3963, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0052, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9444, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4537, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2011, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5342, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0806, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9422, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1268, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0368, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0927, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4416, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1779, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5442, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9799, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9203, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3513, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0877, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7495, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3482, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6360, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6960, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4158, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.6983, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0142, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3939, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.0001, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9485, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2005, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5286, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0830, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9507, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1280, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0310, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0934, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4501, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1810, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5388, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9789, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9283, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3561, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0831, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7469, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3554, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6424, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6926, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4120, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7042, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0217, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3920, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9954, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9529, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4702, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2003, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5233, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0858, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9595, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1296, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0257, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0944, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4588, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1844, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5338, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9782, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9366, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0788, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7447, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6490, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6894, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4085, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7104, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0295, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3903, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9909, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9575, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4788, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2002, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5182, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0886, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9684, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1313, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0204, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0954, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4677, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1879, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5288, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9775, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9449, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3664, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0745, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7423, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3701, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6556, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6863, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4048, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7164, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0372, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3885, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9862, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4872, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2001, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5129, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0912, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9772, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1329, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0149, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0962, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4763, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1912, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5236, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9765, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9530, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3713, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0701, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7397, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3771, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6829, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4008, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7221, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0447, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3865, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9812, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9660, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4954, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1997, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5073, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0935, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9857, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1342, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0091, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0966, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4846, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1942, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5181, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9752, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3759, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0652, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7367, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3838, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6679, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6791, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3965, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7273, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0517, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3840, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9757, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9696, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5031, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1988, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5012, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0954, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9936, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1350, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0028, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0966, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4924, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1967, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5120, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9733, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9678, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3800, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7332, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3899, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6733, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6747, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3914, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7320, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0582, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3810, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9697, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9726, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5102, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1973, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4945, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0965, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0010, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1352, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9959, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0959, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4995, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1986, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5053, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9707, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9743, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3834, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0537, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7289, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3953, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6781, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6697, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3858, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7361, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0640, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3774, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9750, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5167, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1952, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4871, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0970, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0077, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1348, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9883, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0945, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5060, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1998, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4980, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9675, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9801, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3863, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0471, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7240, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4001, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6823, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6641, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3795, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7394, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0692, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3731, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9556, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9767, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5226, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1926, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4791, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0969, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0139, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1338, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9801, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0924, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5119, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2006, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4901, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9636, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9854, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3886, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0399, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7185, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4043, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6860, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6580, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3726, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7422, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0739, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3684, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9478, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9778, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5280, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1895, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4707, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0962, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0195, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1324, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9715, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0900, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5174, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2009, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4818, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9593, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9902, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3905, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0323, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7127, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4081, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6893, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6515, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3654, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7447, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0783, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3634, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9396, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9787, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.5331, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1861, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.4619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0953, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.0249, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1308, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.9627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.0872, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.5226, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2010, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.4732, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.9548, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(112.9948, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3922, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0245, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.7066, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.4117, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6924, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.6449, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(113.3581, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "a = torch.rand(1, requires_grad = True)\n",
        "b = torch.rand(1, requires_grad = True)\n",
        "print('Initial parameters:', a, b)\n",
        "learning_rate = 0.0001\n",
        "for i in range(1000):\n",
        "    predictions = a.expand_as(x_train) * x_train + b.expand_as(x_train)\n",
        "    loss = torch.mean((predictions - y_train) ** 2)\n",
        "    print('loss:', loss)\n",
        "    loss.backward()\n",
        "    a.data.add_(- learning_rate * a.grad.data)\n",
        "    b.data.add_(- learning_rate * b.grad.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh2TS2cwb8XD"
      },
      "source": [
        "通过打印输出的loss结果来看，存在着非常大的震荡，从而导致无法正确估计参数a和b的值"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYnjdbXUb8XD"
      },
      "source": [
        "#### b. 正确版本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mDDbHlTZb8XD",
        "outputId": "2603a1a2-358f-438f-9ae9-beef844e4b1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial parameters: [tensor([0.5726], requires_grad=True), tensor([0.2922], requires_grad=True)]\n",
            "loss: tensor(579.9048, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(208.7134, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(130.8387, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(114.5009, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(111.0733, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.3542, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.2033, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1717, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1650, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1636, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1633, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1633, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1633, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1633, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1632, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1631, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1630, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1629, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1628, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1627, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1626, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1625, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1624, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1623, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1622, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1621, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1620, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1619, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1618, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1617, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1616, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1615, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1614, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1613, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1612, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1611, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1610, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1609, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1608, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1607, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1606, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1605, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1604, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1603, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1602, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1601, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1600, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1599, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1598, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1597, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(110.1596, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "a = torch.rand(1, requires_grad = True) #创建a变量，并随机赋值初始化\n",
        "b = torch.rand(1, requires_grad = True) #创建b变量，并随机赋值初始化\n",
        "print('Initial parameters:', [a, b])\n",
        "learning_rate = 0.0001 #设置学习率\n",
        "for i in range(1000):\n",
        "    predictions = a.expand_as(x_train) * x_train + b.expand_as(x_train)  #计算在当前a、b条件下的模型预测数值\n",
        "    loss = torch.mean((predictions - y_train) ** 2) #通过与标签数据y比较，计算误差\n",
        "    print('loss:', loss)\n",
        "    loss.backward() #对损失函数进行梯度反传\n",
        "    a.data.add_(- learning_rate * a.grad.data)  #利用上一步计算中得到的a的梯度信息更新a中的data数值\n",
        "    b.data.add_(- learning_rate * b.grad.data)  #利用上一步计算中得到的b的梯度信息更新b中的data数值\n",
        "    ### 增加了这部分代码，清空存储在变量a，b中的梯度信息，以免在backward的过程中会反复不停地累加\n",
        "    a.grad.data.zero_() #清空a的梯度数值\n",
        "    b.grad.data.zero_() #清空b的梯度数值"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "2Lrze4vYb8XD",
        "outputId": "fbcbb7f2-03d5-43c1-ffef-d76d747d371e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x_data = x_train.data.numpy() # 获得x包裹的数据\n",
        "plt.figure(figsize = (10, 7)) #设定绘图窗口大小\n",
        "xplot, = plt.plot(x_data, y_train.numpy(), 'o') # 绘制原始数据\n",
        "yplot, = plt.plot(x_data, a.data.numpy() * x_data + b.data.numpy())  #绘制拟合数据\n",
        "plt.xlabel('X') #更改坐标轴标注\n",
        "plt.ylabel('Y') #更改坐标轴标注\n",
        "str1 = str(a.data.numpy()[0]) + 'x +' + str(b.data.numpy()[0]) #图例信息\n",
        "plt.legend([xplot, yplot],['Data', str1]) #绘制图例\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bIKXb8wb8XD"
      },
      "source": [
        "### 3. 测试阶段"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "w0vYOv4gb8XD",
        "outputId": "4f5246a2-d4de-44a2-cd14-9caa0ad80374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([90.2098, 91.2090, 92.2083, 93.2075, 94.2067, 95.2059, 96.2052, 97.2044,\n",
              "        98.2036, 99.2028], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "predictions = a.expand_as(x_test) * x_test + b.expand_as(x_test) #计算模型的预测结果\n",
        "predictions #输出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "eBAt_cxmb8XD",
        "outputId": "1c54ef81-5ced-46f2-8789-3b0cd2d477d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x_data = x_train.data.numpy() # 获得x包裹的数据\n",
        "x_pred = x_test.data.numpy()\n",
        "plt.figure(figsize = (10, 7)) #设定绘图窗口大小\n",
        "plt.plot(x_data, y_train.data.numpy(), 'o') # 绘制训练数据\n",
        "plt.plot(x_pred, y_test.data.numpy(), 's') # 绘制测试数据\n",
        "x_data = np.r_[x_data, x_test.data.numpy()]\n",
        "plt.plot(x_data, a.data.numpy() * x_data + b.data.numpy())  #绘制拟合数据\n",
        "plt.plot(x_pred, a.data.numpy() * x_pred + b.data.numpy(), 'o') #绘制预测数据\n",
        "plt.xlabel('X') #更改坐标轴标注\n",
        "plt.ylabel('Y') #更改坐标轴标注\n",
        "str1 = str(a.data.numpy()[0]) + 'x +' + str(b.data.numpy()[0]) #图例信息\n",
        "plt.legend([xplot, yplot],['Data', str1]) #绘制图例\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "FPhhGE6Pb8XD"
      },
      "source": [
        "\n",
        "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "7JT3qpmOb8XD",
        "outputId": "4555214e-8cb3-47d4-cc45-c3d403986dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "torch.FloatTensor(np.zeros(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "qFCWetKNb8XD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}